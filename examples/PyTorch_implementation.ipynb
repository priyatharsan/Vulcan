{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (__init__.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2862\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-3531fdc4d855>\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    import vulcanai\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\anaconda\\projects\\work\\aifred\\my_fork\\pytorch_migration\\vulcan\\vulcanai\\__init__.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import .net\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import vulcanai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vulcanai import mnist_loader\n",
    "(train_images, train_labels, test_images, test_labels) = mnist_loader.load_fashion_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_one_hot\n",
    "train_labels = get_one_hot(train_labels)\n",
    "test_labels = get_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((-1, 28, 28, 1)).astype(np.float32)\n",
    "test_images = test_images.reshape((-1, 28, 28, 1)).astype(np.float32)\n",
    "train_labels = train_labels.astype(np.int64)\n",
    "test_labels = test_labels.astype(np.int64)\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TMPDataset(Dataset): #Source: https://discuss.pytorch.org/t/problems-with-pytorch-mlp-when-training-the-mnist-dataset-retrieved-from-keras/12918\n",
    "\n",
    "    def __init__(self, a, b, transform=None):\n",
    "        self.x = a\n",
    "        self.y = b\n",
    "        \n",
    "        self.transform = transform;\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.x[idx];\n",
    "        label = self.y[idx];\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item);\n",
    "        \n",
    "        return (item, label);\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y);\n",
    "train_dataset = TMPDataset(test_images, test_labels)\n",
    "test_dataset = TMPDataset(train_images, train_labels)\n",
    "    \n",
    "test_loader = DataLoader(train_dataset, num_workers=1, batch_size=10000)\n",
    "train_loader = DataLoader(test_dataset, shuffle=True, batch_size=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "columns = 4;\n",
    "rows = 5;\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(train_dataset));\n",
    "    img = train_dataset[img_xy][0][:,:,0]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[np.argmax(train_dataset[img_xy][1])])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_conv_config = {\n",
    "    'mode': 'conv',\n",
    "    'filters': [16, 32],\n",
    "    'filter_size': [[5, 5], [5, 5]],\n",
    "    'stride': [[1, 1], [1, 1]],\n",
    "    'pool': {\n",
    "        'mode': 'average_exc_pad',\n",
    "        'stride': [[2, 2], [2, 2]]\n",
    "    }\n",
    "}\n",
    "network_dense_config = {\n",
    "    'mode': 'dense',\n",
    "    'units': [512],\n",
    "    'dropouts': [0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_var = Variable(train_images.shape, requires_grad=True)\n",
    "#y = Variable(train_labels.shape, requires_grad=True)\n",
    "conv_net= net.Network(\n",
    "    name='conv_test',\n",
    "    dimensions= train_images.shape,\n",
    "    input_var=None,\n",
    "    y=None,\n",
    "    config=network_conv_config,\n",
    "    input_network=None,\n",
    "    num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net = net.Network(\n",
    "    name='1_dense',\n",
    "    dimensions=(None, int(train_images.shape[1])),\n",
    "    input_var=0,\n",
    "    y=0,\n",
    "    config=network_dense_config,\n",
    "    input_network={'network': conv_net, 'layer': 4, 'get_params': True},\n",
    "    num_classes=10,\n",
    "    activation='rectify',\n",
    "    pred_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential(\n",
    "  (conv_test_input): Linear(in_features=1, out_features=1, bias=True)\n",
    "  (conv_test_conv2D_0): Sequential(\n",
    "    (0): Conv2d(1, 16, kernel_size=[5, 5], stride=[1, 1])\n",
    "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (conv_test_conv2D_1): Sequential(\n",
    "    (0): Conv2d(16, 32, kernel_size=[5, 5], stride=[1, 1])\n",
    "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (flatten): Flatten()\n",
    "  (1_dense_dense_0): Sequential(\n",
    "    (0): Linear(in_features=32, out_features=512, bias=True)\n",
    "    (1): Dropout(p=0.3)\n",
    "  )\n",
    "  (classification_layer): Sequential(\n",
    "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
    "    (1): Softmax()\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mods = list(dense_net.network.modules())\n",
    "for i in range(1,len(mods)):\n",
    "    m = mods[i]\n",
    "    p = list(m.parameters())\n",
    "    sizes = []\n",
    "    print(m)\n",
    "    for j in range(len(p)):\n",
    "        size = np.array(p[j].size())\n",
    "        sizes.append(size)\n",
    "        print(size)\n",
    "\n",
    "total_bits = 0\n",
    "for i in range(len(sizes)):\n",
    "    s = sizes[i]\n",
    "    bits = np.prod(np.array(s))*bits\n",
    "    print(bits)\n",
    "    total_bits += bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_name, l in dense_net.network.named_children():\n",
    "    if isinstance(l, torch.nn.Sequential):\n",
    "        for subl_name, subl in l.named_children():\n",
    "            for param in subl.parameters():\n",
    "                print(l_name, subl_name, param.size(0))\n",
    "    else:\n",
    "        for param in l.parameters():\n",
    "            print(l_name, param.size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer = dense_net.network\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "#loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [];\n",
    "for epoch in range(5):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq = 0\n",
    "for l_name, l in model.network.named_children():\n",
    "    if isinstance(l, torch.nn.Sequential):\n",
    "        for subl_name, subl in l.named_children():\n",
    "            for param in subl.parameters():\n",
    "                print(subl, param.size(0))\n",
    "\n",
    "    else:       \n",
    "        for param in l.parameters():\n",
    "            print(l, param.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_name, m in model.named_children():\n",
    "    model2.add_module(m_name, m)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, m in enumerate(model2.modules()):\n",
    "    print(type(idx), '->', type(m))\n",
    "    print(idx, '->', m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = torch.nn.Sequential(, model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
